URL;Scopus Id;Authors;Title;Publication Name;Abstract;Volume;Date;DOI;Citations
https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85181168019&origin=inward;SCOPUS_ID:85181168019;;An AutoML-driven Antenna Performance Prediction Model in the Autonomous Driving Radar Manufacturing Process;KSII Transactions on Internet and Information Systems;;17;2023-12-31;10.3837/tiis.2023.12.006;0
https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85183282875&origin=inward;SCOPUS_ID:85183282875;Vijayan R., Mareeswari V., Rathi R., Ephzibah E.P., Harshitha K.S.R.;A comparative analysis of machine learning algorithms on intrusion detection systems;Building Intelligent Systems Using Machine Learning and Deep Learning: Security, Applications and Its Challenges;Internet usage is quite high, and it is also incredibly important in these times. The Internet has been used for domain transactions, file transfers, and a variety of other operations. In addition to these responsibilities, private data has been sent via the internet through various websites as needed. In the middle of transfers and transactions, these websites, online apps, and the internet must be on the watch for assaults. In technical words, it refers to them as packets, and large packets are transferred across an internet network in a second. Furthermore, the likelihood of delivering malicious packets is great. A mechanism is necessary at crucial spots to identify these attacks. So, as part of this study, the proposed system uses machine learning techniques to detect any potentially harmful network activities. These packets might include data that is encrypted or not. The essential concept here is that the system detects any interruption in the network, excluding the decryption of packets. For the implementation, Wireshark, Weka tools, the Anaconda framework, Jupiter, and the Python language have been used in this proposed work. Here, we applied four different algorithms, like Naive Bayes, SVM, KNN, and Random Forest. The accuracy of each algorithm is found, which will prove which algorithm is better for the detection of intrusion. © 2024 Nova Science Publishers, Inc. All rights reserved.;;2023-12-28;;0
https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85183217661&origin=inward;SCOPUS_ID:85183217661;Meher A.K., Sahoo A.K., Sahoo R.;Intelligent systems for future applications using machine learning;Building Intelligent Systems Using Machine Learning and Deep Learning: Security, Applications and Its Challenges;Data is a collection of raw facts and figures that can be generated from various sources such as social media, health, agriculture, stock markets, weather forecasts, etc. Data from different means of communication is increasing every day, such as Facebook, Twitter, Amazon, LinkedIn, etc. Dealing with the massive amounts of data generated from these sources is now a very difficult task. So, in order to maintain the 5'V concept, we have to use modern tools to process the data. Extracting meaningful data from large amounts of data uses data processing, which uses statistical techniques and algorithms, scientific techniques, different techniques, etc. Data science is a multidisciplinary field that uses scientific methods, processes, algorithms, and systems to extract knowledge and insights from structured and unstructured data. Data science is released in the market to process large amounts of data and discover unseen patterns, gain meaningful insights, make business decisions, etc. Most of the tools used in the data science industry are Python, Machine Learning, NoSQL, MongoDB, Hadoop, Spark, etc. Fields directly or indirectly related to data science include statistical learning, machine learning, deep learning, machine learning, image processing, signal processing, natural language processing, predictive modeling, etc. If we see a trend of faster global data growth, then we have to consider data science with many tools. Data science provides a method of collecting, cleaning, integrating, analyzing, visualizing, and processing data to create data products. Due to the high availability of data, data science roles such as data scientist, data engineering, data analyst, process owner, business analyst, etc. constantly emerging. Now the demand is even greater. Data science careers are currently among the highest paying careers in the world. Due to its wide application in various industries, there is a growing demand for data scientists who can analyze complex data and communicate the results effectively. © 2024 Nova Science Publishers, Inc. All rights reserved.;;2023-12-28;;0
https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85183037694&origin=inward;SCOPUS_ID:85183037694;Esan A., Abodunrin O., Sobowale A., Adeyanju I., Okomba N., Omodunbi B., Adebiyi T., Jooda J., Abdul-Hameed T., Asaolu O.;Long-Short-Term Memory Model for Fake News Detection in Nigeria;Ianna Journal of Interdisciplinary Studies;Background: The advent of technology allows information to be passed through the Internet at a breakneck speed and enables the involvement of many individuals in the use of different social media platforms. Propagation of fake news through the Internet has become rampant due to digitalisation, and the spread of fake news can cause irreparable damage to the victims. The conventional approach to fake news detection is time-consuming, hence introducing fake news detection systems. Existing fake news detection systems have yielded low accuracy and are unsuitable in Nigeria. Objective: This research aims to design and implement a framework for fake news detection using the Long-Short Term Memory (LSTM) model. Methodology: The dataset for the model was obtained from Nigerian dailies and Kaggle and pre-processed by removing punctuation marks and stop words, stemming, tokenisation and one hot representation. Feature extraction was done on the datasets to remove outliers. The locally acquired dataset from Nigeria was balanced using Synthetic Minority Oversampling Techniques (SMOTE) Long-Short Term Memory (LSTM), a variant of Recurrent Neural Network (RNN)-which solved the problem of losing gained knowledge and information over a long period faced by RNN-was used as the detection model This model was implemented using Python 3.9. The model detected fake news by classifying real and fake news approaches. The dataset was fed into the model, and the model classified them as either fake or real news by processing the dataset through input and hidden layers of varying numbers of neurons. accuracy F1 score and detection time were used as the evaluation metrics. The results were then compared to some selected machine learning models and a hybrid of convolutional neural networks and long short-term memory models (CNN-LSTM). Results: The result shows that the LSTM model on a balanced dataset performed best as the two news classes were accurately classified, giving an average detection accuracy of 92.86%, which took the model 0.42 seconds to detect whether news was real or fake. Also, 87.50% average detection accuracy was obtained from an imbalanced dataset. Compared to other machine learning models, SVM and CNN-LSTM gave 81.25% accuracy for imbalanced datasets and 82.14% and 78.57% for balanced datasets, respectively. Conclusion: The outcome of this research shows that the deep learning approach outperformed some machine learning models for fake news detection in terms of performance accuracy. Unique contribution: This work has contributed knowledge by employing an LSTM model for detecting Nigerian fake news using an indigenous dataset. Key Recommendation: Future research should increase the data size of indigenous datasets for fake news detection to achieve improved accuracy. © 2023, University of Nigeria Department of Mass Communication. All rights reserved.;5;2023-12-28;;0
https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85181165064&origin=inward;SCOPUS_ID:85181165064;Lee H., Song M.J., Cho Y.-J., Kim D.J., Hong S.-B., Jung S.Y., Lim S.Y.;Supervised machine learning model to predict mortality in patients undergoing venovenous extracorporeal membrane oxygenation from a nationwide multicentre registry;BMJ Open Respiratory Research;Background Existing models have performed poorly when predicting mortality for patients undergoing venovenous extracorporeal membrane oxygenation (VV-ECMO). This study aimed to develop and validate a machine learning (ML)-based prediction model to predict 90-day mortality in patients undergoing VV-ECMO. Methods This study included 368 patients with acute respiratory failure undergoing VV-ECMO from 16 tertiary hospitals across South Korea between 2012 and 2015. The primary outcome was the 90-day mortality after ECMO initiation. The inputs included all available features (n=51) and those from the electronic health record (EHR) systems without preprocessing (n=40). The discriminatory strengths of ML models were evaluated in both internal and external validation sets. The models were compared with conventional models, such as respiratory ECMO survival prediction (RESP) and predicting death for severe acute respiratory distress syndrome on VV-ECMO (PRESERVE). Results Extreme gradient boosting (XGB) (areas under the receiver operating characteristic curve, AUROC 0.82, 95% CI (0.73 to 0.89)) and light gradient boosting (AUROC 0.81 (95% CI 0.71 to 0.88)) models achieved the highest performance using EHR's and all other available features. The developed models had higher AUROCs (95% CI 0.76 to 0.82) than those of RESP (AUROC 0.66 (95% CI 0.56 to 0.76)) and PRESERVE (AUROC 0.71 (95% CI 0.61 to 0.81)). Additionally, we achieved an AUROC (0.75) for 90-day mortality in external validation in the case of the XGB model, which was higher than that of RESP (0.70) and PRESERVE (0.67) in the same validation dataset. Conclusions ML prediction models outperformed previous mortality risk models. This model may be used to identify patients who are unlikely to benefit from VV-ECMO therapy during patient selection. © Author(s) (or their employer(s)) 2023.;10;2023-12-28;10.1136/bmjresp-2023-002025;0
https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85180117347&origin=inward;SCOPUS_ID:85180117347;Bogetti A.T., Leung J.M.G., Chong L.T.;LPATH: A Semiautomated Python Tool for Clustering Molecular Pathways;Journal of Chemical Information and Modeling;"The pathways by which a molecular process transitions to a target state are highly sought-after as direct views of a transition mechanism. While great strides have been made in the physics-based simulation of such pathways, the analysis of these pathways can be a major challenge due to their diversity and variable lengths. Here, we present the LPATH Python tool, which implements a semiautomated method for linguistics-assisted clustering of pathways into distinct classes (or routes). This method involves three steps: 1) discretizing the configurational space into key states, 2) extracting a text-string sequence of key visited states for each pathway, and 3) pairwise matching of pathways based on a text-string similarity score. To circumvent the prohibitive memory requirements of the first step, we have implemented a general two-stage method for clustering conformational states that exploits machine learning. LPATH is primarily designed for use with the WESTPA software for weighted ensemble simulations; however, the tool can also be applied to conventional simulations. As demonstrated for the C7eqto C7axconformational transition of the alanine dipeptide, LPATH provides physically reasonable classes of pathways and corresponding probabilities. © 2023 The Authors. Published by American Chemical Society.";63;2023-12-25;10.1021/acs.jcim.3c01318;0
https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85181149204&origin=inward;SCOPUS_ID:85181149204;Malik I., Baghel A.S.;Evaluation of the pesticides trending trade in India using machine learning and data analytic;AIP Conference Proceedings;In agriculture, pesticides are a crucial tool for boosting crop productivity and safeguarding crops from disease and pests. However, excessive pesticide usage has had negative effects on the ecosystem. Even though the need for pesticides in agriculture has been rising every year, scientists have worked to limit their exposure. Because pesticide usage is growing in agriculture and other industries for a variety of reasons, the global trade in pesticides has been growing every year. Few persons made the false claim that the usage of pesticides is restricted. In this study, the pesticides dataset from the previous six years - which only includes pesticides imported into India in the previous six years - is processed and used to indicate the consumption of pesticides. The commerce in pesticides is expanding quickly in India as a result of growing pesticide consumption and the accuracy of the result is 86%. This dataset is handled using Python's data analytics package and the Support vector machine (SVM) machine learning algorithm. Data analysis is used in this study to determine the pesticide trade market. The market sees an increase in pesticide consumption every year, which is highly bad for the environment. Following data analysis, findings indicate that both pesticide consumption and import of pesticides are increasing in India. Herbicides, a kind of pesticide intended to eliminate weeds (unwanted plants)., are being employed less frequently by researchers. In this study, weeds and crop plants are distinguished using Keras' CNN model, and then herbicides are sprayed over the weeds rather than the crop when the findings are obtained. This model is trained using a training folder with two subfolders, one for crop and one for weed. To assess the model's efficacy, a test folder that has two subfolders and is similar to the training folder is used, 92% of the model is accurate. © 2023 Author(s).;2938;2023-12-22;10.1063/5.0182645;0
https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85183825642&origin=inward;SCOPUS_ID:85183825642;Cabada R.Z., Estrada M.L.B., Beltrán V.M.B.;Deep learning approaches for affective computing in text;Advanced Applications of Generative AI and Natural Language Processing Models;The field of natural language processing (NLP) is one of the first to be addressed since artificial intelligence emerged. NLP has made remarkable advances in recent years thanks to the development of new machine learning techniques, particularly novel deep learning methods such as LSTM networks and transformers. This chapter presents an overview of how deep learning techniques have been applied to NLP in the area of affective computing. The chapter examines traditional and novel deep learning architectures developed for natural language processing (NLP) tasks. These architectures comprise recurrent neural networks (RNNs), long short-term memory (LSTM) networks, and the cutting-edge transformers. Moreover, a methodology for NLP method training and fine-tuning is presented. The chapter also integrates Python code that demonstrates two NLP case studies specializing in the educational domain for text classification and sentiment analysis. In both cases, the transformer-based machine learning model (BERT) produced the best results. © 2024, IGI Global. All rights reserved.;;2023-12-21;10.4018/9798369305027.ch015;0
https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85181739015&origin=inward;SCOPUS_ID:85181739015;Le Brigant A., Deschamps J., Collas A., Miolane N.;Parametric Information Geometry with the Package Geomstats;ACM Transactions on Mathematical Software;We introduce the information geometry module of the Python package Geomstats. The module first implements Fisher-Rao Riemannian manifolds of widely used parametric families of probability distributions, such as normal, gamma, beta, Dirichlet distributions, and more. The module further gives the Fisher-Rao Riemannian geometry of any parametric family of distributions of interest, given a parameterized probability density function as input. The implemented Riemannian geometry tools allow users to compare, average, interpolate between distributions inside a given family. Importantly, such capabilities open the door to statistics and machine learning on probability distributions. We present the object-oriented implementation of the module along with illustrative examples and show how it can be used to perform learning on manifolds of parametric probability distributions. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.;49;2023-12-15;10.1145/3627538;1
https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85166551588&origin=inward;SCOPUS_ID:85166551588;F. Al-Khafaji H., Meng Q., Hussain W., Khudhair Mohammed R., Harash F., Alshareef AlFakey S.;Predicting minimum miscible pressure in pure CO<inf>2</inf> flooding using machine learning: Method comparison and sensitivity analysis;Fuel;CO2injection for enhanced oil recovery (EOR) is widely recognized as an efficient technique for carbon capture, utilization, and storage (CCUS). This operation has a significant impact on various technical parameters, emphasizing the need to carefully consider and select the optimum approach. Among these factors, the minimum miscible pressure (MMP) plays a crucial role in determining the effectiveness and performance of CO2injection. Therefore, this study aims to assess the reliability of machine learning (ML) in predicting the MMP of pure CO2and examine the influence of different independent parameters. To achieve this, five ML methods were employed to predict the pure CO2MMP, and the results were compared to statistical evaluations based on empirical correlations. In addition, three types of data with different functional input parameters were used in this research. Two types of data were obtained from existing literature, while the third category was collected from the thesis and PVT reports for specific Iraqi oil fields. The ML models were constructed by splitting the dataset into 20% for testing and 80% for training using Python programming. The significance of this study lies in its ability to identify the most efficient approach for forecasting MMP. The results of this work revealed that the K-nearest neighbors (KNN) model indicated the best statistical evaluation among the ML learning algorithms for two types of data (2) and (3) in predicting the MMP for pure CO2flooding. This was evidenced by the lowest mean square error and the highest coefficient of determination. Additionally, the findings indicated that the support vector regression (SVR) method is an effective technique for smaller datasets. Moreover, the sensitivity analysis and assessment of the relative impacts of various input parameters revealed that the prediction of MMP is most sensitive to the composition of the injected gas and temperature, accounting for 46% and 28.5% of the variation, respectively. Finally, the presented ML models indicate exceptional accuracy, speed, adaptability in handling diverse conditions, and cost-effectiveness when compared to conventional approaches. These results verify the ability of ML models to provide high-quality predictions. © 2023 Elsevier Ltd;354;2023-12-15;10.1016/j.fuel.2023.129263;3
https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85183545264&origin=inward;SCOPUS_ID:85183545264;;HCAIep 2023 - Proceedings of the 2023 Conference on Human Centered Artificial Intelligence - Education and Practice;ACM International Conference Proceeding Series;"The proceedings contain 21 papers. The topics discussed include: explainability in NLP model: detection of Covid-19 twitter fake news; automated lip reading: enhancing accessibility measures in XR for education; teachers’ motivation for teaching AI in K-12 settings; human-centered AI education in upper-second level: towards a PRIMM-Esque pedagogy for CT 2.0; integrating human factors into trustworthy AI for healthcare; personalized programming education with knowledge tracing; immersive neural network exploration: a VR approach to human-centered AI understanding; promoting human-centered machine translation quality assessment in NLP education; exploring the research gap: generative AI and learning of python programming among post-primary students; and algorithmic biases in causal structure learning for gene regulatory networks.";;2023-12-14;;0
https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85180543309&origin=inward;SCOPUS_ID:85180543309;Al Ibrahim M.A.;An open source toolbox to automate basin and petroleum system modeling for statistical analysis and uncertainty quantification;SEG Technical Program Expanded Abstracts;Basin and petroleum system modeling is an important process to understand and validate petroleum concepts. Traditionally, the models are constructed, calibrated, and examined manually. This can be time-consuming as the number of parameters used in these models and their associated uncertainties is commonly large. The objective of this work is to enable advanced statistical analysis to basin and petroleum modeling simulation by enabling automation of model modification, model running, and interrogation of simulation results. An open source toolbox is developed using Python to control basin and petroleum system modeling simulations. Inputs and outputs are presented to user in the standard formats used in the Python scientific stack, e.g., Python objects, numpy arrays, and Pandas data frames. This allows integration with the large wealth of open source scientific and statistical packages available in the community. Model parameters that can be automatically updated include burial history, heat flow, and paleowater depth. Other parameters such as lithologic parameters and source rock kinetics can also be updated. Practically, a project and starting template model is created in the software. This template is then modified automatically using the toolbox. For example, the model can be duplicated, modified, run automatically, and results are extracted. Generally, two workflows are followed: sequential, and parallel. In sequential workflows, such as in some workflows related to automated calibration, the toolbox can assist by removing human interactions between runs. In parallel workflows, such as in some sensitivity analysis workflows, multiple models can be simulated in parallel and thereby reduce the time it takes to reach the final results. We show that such toolbox is useful for practical applications related to basin and petroleum system modeling such parameter sensitivity analysis, automated calibration, and uncertainty quantification in Bayesian frameworks. For example, model sensitivity studies are run by sampling model parameters from prior distributions to construct model realizations. These constructed models are run in parallel. The results are then loaded back into the toolbox and analyzed using sensitivity analysis methods such as distance-based global sensitivity analysis. Another example is the use of parameter optimization toolkits to automatically calibrate basin models to observed well data, such as by modifying lithological parameters such as compaction model, and porosity-permeability relationships Overall, the toolbox can be utilized in researching new workflows and in operational setting to construct end-to-end solutions related to basin and petroleum system modeling. In operational setting, graphical user interfaces are constructed for ease of use based on the user needs. Thus, all complexities of coding are hidden from the user. The application programming interface toolbox extends an existing established basin and petroleum system modeling simulator. Thus, it is of use to the practicing geoscientists, especially with the move towards geoscientific analyses while taking uncertainty into account. The toolbox also opens more advanced opportunities such as accelerating automated calibration by combining machine learning proxy models with traditional basin and petroleum system modeling simulators. © 2023 Society of Exploration Geophysicists and the American Association of Petroleum Geologists.;2023-August;2023-12-14;10.1190/image2023-3914751.1;0
https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85180541795&origin=inward;SCOPUS_ID:85180541795;Silver A.C.;Enabling grassroots digital transformation with a Python-Excel ML Toolkit;SEG Technical Program Expanded Abstracts;A Python-Excel ML Toolkit was developed which enables grassroots digital transformation by implementing ML tools in Excel's familiar environment without users needing to code in Python. This was done by linking multivariate machine learning (ML) algorithms coded in Python to the Excel application. The resulting toolkit empowers knowledge workers such as geoscientists, petrophysicists, and engineers. © 2023 Society of Exploration Geophysicists and the American Association of Petroleum Geologists.;2023-August;2023-12-14;10.1190/image2023-w12-01.1;0
https://www.scopus.com/inward/record.uri?partnerID=HzOxMe3b&scp=85180538278&origin=inward;SCOPUS_ID:85180538278;Farris S., Barnier G., Biondi E., Clapp R.;pyseis: a high-performance, user-friendly Python package for GPU-accelerated seismic modeling and subsurface imaging;SEG Technical Program Expanded Abstracts;pyseis, a high-performance Python library, harnesses the power of low-level CUDA and C++ for computation, and provides a user-friendly Python interface for wave-equation modeling and inversion. It incorporates acoustic and elastic finite-difference solvers, adjoint state-based gradients, and seismic imaging and inversion support. Speed benchmarks, along with a sample FWI implementation, showcase the robustness of pyseis. Moreover, its capabilities are exemplified in tackling complex seismic problems, from elastic FWI and FWI by Model Extension to machine learning applications in seismic inversion. pyseis serves as a versatile and efficient tool for geophysicists, enabling them to perform intricate seismic computations with ease. The code is available at http://zapad.stanford.edu/sfarris/pyseis. © 2023 Society of Exploration Geophysicists and the American Association of Petroleum Geologists.;2023-August;2023-12-14;10.1190/image2023-3916155.1;0
